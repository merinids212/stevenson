<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover">
<title>STEVENSON — About</title>
<link rel="icon" type="image/svg+xml" href="favicon.svg">
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@400;500;600&display=swap" rel="stylesheet">
<link rel="stylesheet" href="stv-nav.css">
<style>
  *, *::before, *::after {
    box-sizing: border-box;
    margin: 0;
    padding: 0;
  }

  :root {
    --font: 'IBM Plex Mono', monospace;
    --black: #000;
    --white: #fff;
    --gray: #999;
    --ease: cubic-bezier(0.4, 0, 0.2, 1);
  }

  html, body {
    height: 100%;
    font-family: var(--font);
    background: var(--white);
    color: var(--black);
    -webkit-font-smoothing: antialiased;
  }

  ::-webkit-scrollbar { width: 0; height: 0; }

  .about-content {
    max-width: 560px;
    margin: 0 auto;
    padding: calc(48px + env(safe-area-inset-top, 0px) + 60px) 24px 80px;
  }

  .about-content h1 {
    font-size: 14px;
    font-weight: 500;
    letter-spacing: 0.05em;
    text-transform: uppercase;
    margin-bottom: 40px;
  }

  .about-content h2 {
    font-size: 11px;
    font-weight: 600;
    letter-spacing: 0.08em;
    text-transform: uppercase;
    color: var(--gray);
    margin-top: 48px;
    margin-bottom: 16px;
  }

  .about-content p {
    font-size: 13px;
    line-height: 1.8;
    color: #333;
    margin-bottom: 24px;
  }

  .about-content .stat {
    display: flex;
    justify-content: space-between;
    padding: 12px 0;
    border-bottom: 1px solid #f0f0f0;
    font-size: 12px;
    text-transform: uppercase;
    letter-spacing: 0.03em;
  }

  .about-content .stat-value {
    color: var(--gray);
  }

  .about-stats {
    margin-top: 48px;
    margin-bottom: 48px;
  }

</style>
</head>
<body>

<nav class="stv-nav" data-stv-theme="light" data-stv-page="about">
  <div class="stv-nav-center">
    <a class="stv-nav-back" href="/">&#8249;</a>
    <span class="stv-nav-title">About</span>
  </div>
</nav>

<div class="about-content">
  <h1>Stevenson</h1>

  <p>
    An art discovery engine that continuously crawls painting listings
    from Craigslist and eBay across the United States, scores them with
    computer vision models, and serves a curated gallery — surfacing
    the most interesting work from the most unexpected places.
  </p>

  <p>
    No accounts, no fees, no middlemen. Just paintings and the
    people selling them.
  </p>

  <div class="about-stats" id="stats"></div>

  <h2>Vision Scoring</h2>

  <p>
    Every painting is processed by a CLIP ViT-L/14 vision transformer to
    extract a 768-dimensional embedding — a numerical fingerprint of
    what the image "looks like" to a neural network. These embeddings
    are then scored by a LAION aesthetic predictor, a model trained on
    millions of human aesthetic preference ratings, calibrated to a
    0–100 scale.
  </p>

  <p>
    On top of the aesthetic score, each painting is evaluated for visual
    quality (how closely it resembles professionally photographed fine art
    versus casual snapshots) and uniqueness (how different it is from
    everything else in the collection, measured by cosine distance in
    embedding space). These three signals — aesthetics, quality, and
    uniqueness — are blended into a composite art score.
  </p>

  <h2>Style Classification</h2>

  <p>
    CLIP's zero-shot classification capability is used to identify
    the medium and style of each painting — oil, watercolor, acrylic,
    pastel, ink, digital, and others — along with subject matter like
    landscape, portrait, abstract, and still life. Artist names are
    parsed from listing titles using pattern matching. Together,
    these labels power the analytics breakdowns and filtered views.
  </p>

  <h2>Taste Learning</h2>

  <p>
    The feed learns from your likes in real time. As you heart paintings,
    the system builds a taste profile from the CLIP embeddings of
    your liked works. When you've liked enough paintings, the algorithm
    identifies distinct "poles" in your taste — maybe you're drawn to both
    moody seascapes and vibrant street scenes — and queries each pole
    separately, ensuring your feed stays diverse rather than collapsing
    into a single aesthetic.
  </p>

  <p>
    Style affinity and price range are used as light signals — gentle
    nudges within small windows, never hard filters — so the feed
    feels personalized without becoming a filter bubble.
  </p>

  <h2>Gem Finding</h2>

  <p>
    A value score identifies underpriced work — paintings with high
    aesthetic quality relative to their asking price. The GEMS filter
    surfaces these finds: technically accomplished paintings that
    happen to be listed cheaply, often by sellers who don't know
    what they have.
  </p>

  <h2>The Taste Map</h2>

  <p>
    All 768-dimensional embeddings are projected into three dimensions
    using UMAP (Uniform Manifold Approximation and Projection), a
    manifold learning technique that preserves the local neighborhood
    structure of high-dimensional data. The result is a navigable 3D
    point cloud where similar paintings cluster together — oil landscapes
    in one region, abstract acrylics in another, portraits forming
    their own galaxy. Your liked paintings appear as bright red dots,
    revealing the shape of your taste in embedding space.
  </p>

  <h2>Infrastructure</h2>

  <p>
    Crawlers run on a schedule, collecting new listings and deduplicating
    against existing data. Scoring runs on Apple Silicon using Metal
    Performance Shaders for GPU-accelerated inference. All painting data,
    scores, embeddings, and UMAP coordinates are stored in Redis with
    sorted set indexes for fast filtered queries. The frontend is static
    HTML served by Vercel with serverless TypeScript API functions.
    No build step, no framework — just HTML, CSS, and JavaScript.
  </p>

</div>

<script>
  fetch('/api/stats')
    .then(r => r.json())
    .then(s => {
      const stats = [
        ['Total listings', parseInt(s.total_listings).toLocaleString()],
        ['Sources', 'Craigslist + eBay'],
        ['Regions', s.regions],
        ['Price range', `$${parseFloat(s.price_min).toLocaleString()} \u2014 $${parseFloat(s.price_max).toLocaleString()}`],
        ['Median price', `$${parseFloat(s.price_median).toLocaleString()}`],
        ['Vision scored', parseInt(s.scored_count).toLocaleString()],
        ['Artists identified', parseInt(s.artists_count).toLocaleString()],
        ['Vision model', 'CLIP ViT-L/14'],
        ['Aesthetic model', 'LAION Improved Aesthetic Predictor'],
        ['Embedding dimensions', '768'],
      ];

      const container = document.getElementById('stats');
      stats.forEach(([label, value]) => {
        container.innerHTML += `<div class="stat"><span>${label}</span><span class="stat-value">${value}</span></div>`;
      });
    });
</script>
<script src="stv-nav.js"></script>
</body>
</html>
